{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    ".master(\"local[4]\") \\\n",
    ".appName(\"Csv-Üzeri-SQL\") \\\n",
    ".config(\"spark.executor.memory\",\"4g\") \\\n",
    ".config(\"spark.driver.memory\",\"2g\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will take only data-time column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    ".option(\"header\",\"True\") \\\n",
    ".option(\"inferSchema\",\"True\") \\\n",
    ".option(\"sep\",\";\") \\\n",
    ".csv(\"C:\\\\Users\\\\alican\\\\Desktop\\\\BigData\\\\OnlineRetail.csv\") \\\n",
    ".select(\"InvoiceDate\").distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|     InvoiceDate|\n",
      "+----------------+\n",
      "| 3.12.2010 16:50|\n",
      "| 7.12.2010 12:28|\n",
      "| 8.12.2010 15:02|\n",
      "|10.12.2010 09:53|\n",
      "|12.12.2010 13:32|\n",
      "|15.12.2010 13:21|\n",
      "|16.12.2010 08:41|\n",
      "|17.12.2010 09:52|\n",
      "| 9.01.2011 11:43|\n",
      "|11.01.2011 11:38|\n",
      "|16.01.2011 15:50|\n",
      "|25.01.2011 17:06|\n",
      "|27.01.2011 12:10|\n",
      "|28.01.2011 12:19|\n",
      "|31.01.2011 12:16|\n",
      "| 1.02.2011 10:04|\n",
      "| 2.02.2011 11:16|\n",
      "| 7.02.2011 15:01|\n",
      "|11.02.2011 15:56|\n",
      "|15.02.2011 13:52|\n",
      "+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evet şimdi anlaşıldı. Format gün.ay.yıl saat:dakika yani dd.MM.yyyy HH:mm\n",
    "\n",
    "# Datetime da ise varsayılan format yyyy-MM-dd HH:mm:ss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "exits_format = 'dd.MM.yyyy HH:mm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE DATE AND TIME OPERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df2 = df.withColumn(\"InvoiceDate\", F.trim(F.col(\"InvoiceDate\"))) \\\n",
    ".withColumn(\"normal_dates_struct\", F.to_date(F.col(\"InvoiceDate\"), exits_format)) \\\n",
    ".withColumn(\"standart_dates_struct\", F.to_timestamp(F.col(\"InvoiceDate\"), exits_format)) \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+---------------------+\n",
      "|     InvoiceDate|normal_dates_struct|standart_dates_struct|\n",
      "+----------------+-------------------+---------------------+\n",
      "| 3.12.2010 16:50|         2010-12-03|  2010-12-03 16:50:00|\n",
      "| 7.12.2010 12:28|         2010-12-07|  2010-12-07 12:28:00|\n",
      "| 8.12.2010 15:02|         2010-12-08|  2010-12-08 15:02:00|\n",
      "|10.12.2010 09:53|         2010-12-10|  2010-12-10 09:53:00|\n",
      "|12.12.2010 13:32|         2010-12-12|  2010-12-12 13:32:00|\n",
      "|15.12.2010 13:21|         2010-12-15|  2010-12-15 13:21:00|\n",
      "|16.12.2010 08:41|         2010-12-16|  2010-12-16 08:41:00|\n",
      "|17.12.2010 09:52|         2010-12-17|  2010-12-17 09:52:00|\n",
      "| 9.01.2011 11:43|         2011-01-09|  2011-01-09 11:43:00|\n",
      "|11.01.2011 11:38|         2011-01-11|  2011-01-11 11:38:00|\n",
      "+----------------+-------------------+---------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- normal_dates_struct: date (nullable = true)\n",
      " |-- standart_dates_struct: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGING DATE FORMAT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+---------------------+-------------------+-------------------+----------+\n",
      "|     InvoiceDate|normal_dates_struct|standart_dates_struct|            TIME_TR|           TIME_ENG| unix_time|\n",
      "+----------------+-------------------+---------------------+-------------------+-------------------+----------+\n",
      "| 3.12.2010 16:50|         2010-12-03|  2010-12-03 16:50:00|03/12/2010 16:50:00|12-03-2010 16:50:00|1291387800|\n",
      "| 7.12.2010 12:28|         2010-12-07|  2010-12-07 12:28:00|07/12/2010 12:28:00|12-07-2010 12:28:00|1291717680|\n",
      "| 8.12.2010 15:02|         2010-12-08|  2010-12-08 15:02:00|08/12/2010 15:02:00|12-08-2010 15:02:00|1291813320|\n",
      "|10.12.2010 09:53|         2010-12-10|  2010-12-10 09:53:00|10/12/2010 09:53:00|12-10-2010 09:53:00|1291967580|\n",
      "|12.12.2010 13:32|         2010-12-12|  2010-12-12 13:32:00|12/12/2010 13:32:00|12-12-2010 13:32:00|1292153520|\n",
      "|15.12.2010 13:21|         2010-12-15|  2010-12-15 13:21:00|15/12/2010 13:21:00|12-15-2010 13:21:00|1292412060|\n",
      "|16.12.2010 08:41|         2010-12-16|  2010-12-16 08:41:00|16/12/2010 08:41:00|12-16-2010 08:41:00|1292481660|\n",
      "|17.12.2010 09:52|         2010-12-17|  2010-12-17 09:52:00|17/12/2010 09:52:00|12-17-2010 09:52:00|1292572320|\n",
      "| 9.01.2011 11:43|         2011-01-09|  2011-01-09 11:43:00|09/01/2011 11:43:00|01-09-2011 11:43:00|1294566180|\n",
      "|11.01.2011 11:38|         2011-01-11|  2011-01-11 11:38:00|11/01/2011 11:38:00|01-11-2011 11:38:00|1294738680|\n",
      "+----------------+-------------------+---------------------+-------------------+-------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_tr = \"dd/MM/yyyy HH:mm:ss\"\n",
    "format_eng = \"MM-dd-yyyy HH:mm:ss\"\n",
    "\n",
    "df3 = df2 \\\n",
    ".withColumn(\"TIME_TR\", F.date_format(F.col(\"standart_dates_struct\"), format_tr)) \\\n",
    ".withColumn(\"TIME_ENG\", F.date_format(F.col(\"standart_dates_struct\"), format_eng)) \\\n",
    ".withColumn(\"unix_time\", F.unix_timestamp(F.col(\"standart_dates_struct\"))) \\\n",
    "\n",
    "df3.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDING DATE , DATE DIFFERENCE ,YEAR SEARCHING INTO TIMESTAMP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df2 \\\n",
    ".withColumn(\"one_year_added\", F.date_add(F.col(\"standart_dates_struct\"), 365)) \\\n",
    ".withColumn(\"year\", F.year(F.col(\"standart_dates_struct\"))) \\\n",
    ".withColumn(\"fark\", F.datediff(F.col(\"one_year_added\"), F.col(\"standart_dates_struct\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------------------+---------------------+--------------+----+----+\n",
      "|     InvoiceDate|normal_dates_struct|standart_dates_struct|one_year_added|year|fark|\n",
      "+----------------+-------------------+---------------------+--------------+----+----+\n",
      "| 3.12.2010 16:50|         2010-12-03|  2010-12-03 16:50:00|    2011-12-03|2010| 365|\n",
      "| 7.12.2010 12:28|         2010-12-07|  2010-12-07 12:28:00|    2011-12-07|2010| 365|\n",
      "| 8.12.2010 15:02|         2010-12-08|  2010-12-08 15:02:00|    2011-12-08|2010| 365|\n",
      "|10.12.2010 09:53|         2010-12-10|  2010-12-10 09:53:00|    2011-12-10|2010| 365|\n",
      "|12.12.2010 13:32|         2010-12-12|  2010-12-12 13:32:00|    2011-12-12|2010| 365|\n",
      "|15.12.2010 13:21|         2010-12-15|  2010-12-15 13:21:00|    2011-12-15|2010| 365|\n",
      "|16.12.2010 08:41|         2010-12-16|  2010-12-16 08:41:00|    2011-12-16|2010| 365|\n",
      "|17.12.2010 09:52|         2010-12-17|  2010-12-17 09:52:00|    2011-12-17|2010| 365|\n",
      "| 9.01.2011 11:43|         2011-01-09|  2011-01-09 11:43:00|    2012-01-09|2011| 365|\n",
      "|11.01.2011 11:38|         2011-01-11|  2011-01-11 11:38:00|    2012-01-11|2011| 365|\n",
      "+----------------+-------------------+---------------------+--------------+----+----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
